Dataset to train models on chessboards' squares being or not occupied by pieces (of any color).
Formed with all images from chessRed2k dataset, and around 2000 images from OSF_dataset (in an attempt to balance the amount of images from each dataset). The first dataset is of a wooden board, with light brown and dark brown squares and piece sets. The second is of a plastic foldable set, with black and white/cream squares and piece sets.

Each of these images contained information of the chessboards' corners. From here, the image was warped to obtain a square shape of the chessboard, and each square of the chessboard was cropped into an individual image, with some extra space around the square to provide more context for the model to correctly infer if the square is or not occupied. This way, each original image yielded 64 square images of size 100x100. I choose this size because it corresponded to the input image size that the vanilla CNN would receive, thus minimizing storage.

Due to much higher amount of non-occupied squares in relation to occupied squares in datasets, augmentation techniques were used to increase the non-occupied squares. Augmentation involved left-right flipping of existent images, change in brightness, contrast, saturation and hue. I did not apply warping or rescale of these images since I wanted to maintaining square size as 100x100.

From two types of model tested:
- Vanilla CNNs with 3 conv-pooling layers, followed by 3 dense layers
- Resnet50 + globalAvgPooling layer + denseLayer

The best performing models were of the resnet50 adaptation, with around 85% accuracy.

Main issues:
- Unused a lot of images from OSF_dataset -> should use as much data as possible
- Due to the way images were warped, many individual squares images have chess pieces that are not vertically aligned or are upside down. -> the model is training on unrealistic scenarios, since in the photos i will feed it after training, the pieces will always be aligned vertically correctly.
- Image size is only 100x100 but resnet50 model receives 224x224 size images -> subtle features that are important for classification might have been lost in image size reduction
- In augmentation, I didn't apply warping or rescaling to the square images, for reasons already stated. However, I could apply these augmentations to the chessboard images before square partitioning, thus making the images have broader angles and perspectives, which would ultimately result in more varied square individual images (while still maintaining the required 100x100 or 224x224 size images)

I will make a new dataset with this aspects in mind..
